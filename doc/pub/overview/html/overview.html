<!--
Automatically generated HTML file from DocOnce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Machine Learning and AI in Nuclear Physics">

<title>Machine Learning and AI in Nuclear Physics</title>


<style type="text/css">
/* bloodish style */

body {
  font-family: Helvetica, Verdana, Arial, Sans-serif;
  color: #404040;
  background: #ffffff;
}
h1 { font-size: 1.8em;  color: #8A0808; }
h2 { font-size: 1.6em;  color: #8A0808; }
h3 { font-size: 1.4em;  color: #8A0808; }
h4 { color: #8A0808; }
a { color: #8A0808; text-decoration:none; }
tt { font-family: "Courier New", Courier; }
/* pre style removed because it will interfer with pygments */
p { text-indent: 0px; }
hr { border: 0; width: 80%; border-bottom: 1px solid #aaa}
p.caption { width: 80%; font-style: normal; text-align: left; }
hr.figure { border: 0; width: 80%; border-bottom: 1px solid #aaa}
.alert-text-small   { font-size: 80%;  }
.alert-text-large   { font-size: 130%; }
.alert-text-normal  { font-size: 90%;  }
.alert {
  padding:8px 35px 8px 14px; margin-bottom:18px;
  text-shadow:0 1px 0 rgba(255,255,255,0.5);
  border:1px solid #bababa;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  -moz-border-radius: 4px;
  color: #555;
  background-color: #f8f8f8;
  background-position: 10px 5px;
  background-repeat: no-repeat;
  background-size: 38px;
  padding-left: 55px;
  width: 75%;
 }
.alert-block {padding-top:14px; padding-bottom:14px}
.alert-block > p, .alert-block > ul {margin-bottom:1em}
.alert li {margin-top: 1em}
.alert-block p+p {margin-top:5px}
.alert-notice { background-image: url(https://cdn.rawgit.com/hplgit/doconce/master/bundled/html_images/small_gray_notice.png); }
.alert-summary  { background-image:url(https://cdn.rawgit.com/hplgit/doconce/master/bundled/html_images/small_gray_summary.png); }
.alert-warning { background-image: url(https://cdn.rawgit.com/hplgit/doconce/master/bundled/html_images/small_gray_warning.png); }
.alert-question {background-image:url(https://cdn.rawgit.com/hplgit/doconce/master/bundled/html_images/small_gray_question.png); }

div { text-align: justify; text-justify: inter-word; }
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Machine Learning and AI and Nuclear Physics',
               2,
               None,
               '___sec0'),
              ('What is Machine Learning?', 2, None, '___sec1'),
              ('A new world', 2, None, '___sec2'),
              ('Lots of room for creativity', 2, None, '___sec3'),
              ('Types of Machine Learning', 2, None, '___sec4'),
              ('Why Machine Learning and Nuclear Physics, Motivation',
               2,
               None,
               '___sec5'),
              ('Further Motivation', 2, None, '___sec6'),
              ('A simple perspective on the interface between ML and Physics',
               2,
               None,
               '___sec7'),
              ('ML in Nuclear Physics, Examples', 2, None, '___sec8'),
              ('More examples', 2, None, '___sec9'),
              ('Education and Work force development', 2, None, '___sec10'),
              ('References', 2, None, '___sec11')]}
end of tocinfo -->

<body>

    
<!-- ------------------- main content ---------------------- -->



<center><h1>Machine Learning and AI in Nuclear Physics</h1></center>  <!-- document title -->

<p>
<!-- author(s): Daniel Bazin, Scott Bogner, Alexandra Gade, Heiko Hergert, Morten Hjorth-Jensen, Dean Lee, Sean Liddick, Witek Nazarewicz and Andrea Shindler -->

<center>
<b>Daniel Bazin, Scott Bogner, Alexandra Gade, Heiko Hergert, Morten Hjorth-Jensen, Dean Lee, Sean Liddick, Witek Nazarewicz and Andrea Shindler</b> 
</center>

<p>
<!-- institution -->

<center><b>Department of Physics and Astronomy and Facility for Rare Ion Beams and National Superconducting Cyclotron Laboratory, Michigan State University, USA</b></center>
<br>
<p>
<center><h4>Talking points</h4></center> <!-- date -->
<br>
<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec0">Machine Learning and AI and Nuclear Physics </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>

<p>
Artificial intelligence-based techniques, particularly in machine
learning and optimization, are increasingly being used in many areas
of experimental and theoretical physics to facilitate discovery,
accelerate data analysis and modeling efforts, and bridge different
physical and temporal scales in numerical models.

<p>
These techniques are proving to be powerful tools for advancing our
understanding; however, they are not without significant
challenges. The theoretical foundations of many tools, such as deep
learning, are poorly understood, resulting in the use of techniques
whose behavior (and misbehavior) is difficult to predict and
understand. Similarly, physicists typically use general AI techniques
that are not tailored to the needs of the experimental and theoretical
work being done. Thus, many opportunities exist for major advances
both in physical discovery using AI and in the theory of
AI. Furthermore, there are tremendous opportunities for these fields
to inform each other, for example, in creating machine learning- based
methods that must obey certain constraints by design, such as the
conservation of mass, momentum and energy.


</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec1">What is Machine Learning? </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
Machine learning is the science of giving computers the ability to
learn without being explicitly programmed.  The idea is that there
exist generic algorithms which can be used to find patterns in a broad
class of data sets without having to write code specifically for each
problem. The algorithm will build its own logic based on the data.

<p>
Machine learning is a subfield of computer science, and is closely
related to computational statistics.  It evolved from the study of
pattern recognition in artificial intelligence (AI) research, and has
made contributions to AI tasks like computer vision, natural language
processing and speech recognition. It has also, especially in later
years, found applications in a wide variety of other areas, including
bioinformatics, economy, physics, finance and marketing.


</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec2">A new world </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
Machine learning (ML) is an extremely rich field, in spite of its young age. The
increases we have seen during the last three decades in computational
capabilities have been followed by developments of methods and
techniques for analyzing and handling large date sets, relying heavily
on statistics, computer science and mathematics.  The field is rather
new and developing rapidly.

<p>
Popular software packages written in Python for ML are

<ul>
<li> <a href="http://scikit-learn.org/stable/" target="_blank">Scikit-learn</a>,</li> 
<li> <a href="https://www.tensorflow.org/" target="_blank">Tensorflow</a>,</li>
<li> <a href="http://pytorch.org/" target="_blank">PyTorch</a></li>
<li> <a href="https://keras.io/" target="_blank">Keras</a>,</li>
</ul>

and more. These are all freely available at their respective GitHub sites. They 
encompass communities of developers in the thousands or more. And the number
of code developers and contributors keeps increasing.
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec3">Lots of room for creativity </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
Not all the
algorithms and methods can be given a rigorous mathematical
justification, opening up thereby for experimenting
and trial and error and thereby exciting new developments.
</div>


<p>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
A solid command of linear algebra, multivariate theory, 
probability theory, statistical data analysis, optimization algorithms, 
understanding errors and Monte Carlo methods is important in order to understand many of the 
various algorithms and methods.
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec4">Types of Machine Learning </h2>

<p>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
The approaches to machine learning are many, but are often split into two main categories. 
In <em>supervised learning</em> we know the answer to a problem,
and let the computer deduce the logic behind it. On the other hand, <em>unsupervised learning</em>
is a method for finding patterns and relationship in data sets without any prior knowledge of the system.
Some authours also operate with a third category, namely <em>reinforcement learning</em>. This is a paradigm 
of learning inspired by behavioural psychology, where learning is achieved by trial-and-error, 
solely from rewards and punishment.

<p>
Another way to categorize machine learning tasks is to consider the desired output of a system.
Some of the most common tasks are:

<ul>
  <li> Classification: Outputs are divided into two or more classes. The goal is to   produce a model that assigns inputs into one of these classes. An example is to identify  digits based on pictures of hand-written ones. Classification is typically supervised learning.</li>
  <li> Regression: Finding a functional relationship between an input data set and a reference data set.   The goal is to construct a function that maps input data to continuous output values.</li>
  <li> Clustering: Data are divided into groups with certain common traits, without knowing the different groups beforehand.  It is thus a form of unsupervised learning.</li>
</ul>
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec5">Why Machine Learning and Nuclear Physics, Motivation </h2>

<p>
Techniques based on artificial intelligence (AI), particularly in
machine learning (ML) and optimization, are increasingly being used in
many areas of experimental and theoretical physics to facilitate
discovery, accelerate data analysis and modeling efforts, and bridge
different physical and temporal scales in numerical models. These 
techniques are proving to be powerful tools for advancing our physical
understanding; however, they are not without significant challenges
of their own. The theoretical foundations of many AI tools, such as
deep learning, are poorly understood, resulting in the use of
techniques whose behavior (and misbehavior) is difficult to predict
and understand. Similarly, physicists typically use general AI
techniques that are not tailored to the needs of the experimental and
theoretical work being done. As a consequence, there is a profound
need for major advances both in the ways that AI techniques are used
in physics and in the theoretical foundations of AI
methods. Furthermore, there are tremendous opportunities for these
fields to inform each other, for example, in creating ML-based
methods that must obey physical constraints by design, e.g.,
conservation of energy.

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec6">Further Motivation  </h2>

<p>
Physics has historically been on the forefront of the data revolution,
and the future will be no different. Upcoming expansions to the
Large Hadron Collider will increase data rates by an order of
magnitude past their previous peak, and high-current nuclear physics
facilities such as the DOE&#8217;s Facility for Rare Isotope Beams will also
have incredibly high rates of data production. These laboratories and experiments
will produce large and rich (but
complicated) time-sequence datasets. In theoretical physics, the need
to address such experiments requires sophisticated, multiphysics
numerical simulations that span a wide range of spatial and temporal
scales, physical models (e.g., particle vs. continuum ap-
proximations). Even with the advent of exascale
computing, approximations must be made in order to make the problems
computationally tractable.

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec7">A simple perspective on the interface between ML and Physics </h2>

<p>
<br /><br /><center><p><img src="figures/mlimage.png" align="bottom" width=700></p></center><br /><br />

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec8">ML in Nuclear Physics, Examples </h2>

<p>
The large amount of degrees of freedom pertain to both theory and experiemtn in nuclear physics. With increasingly complicated experiments that produce large amounts data, automated classification of events becomes increasingly important. Here, deep learning methods offer a plethora of interesting research avenues. 

<ul>
<li> Reconstruction of particle trajectories or classification of events are typical examples where ML methods are being used. However, since these data can often be extremely noisy, the precision necessary for discovery in physics requires algorithmic improvements. Research along such directions, interfacing nuclear physics with AI/ML is expected to play a significant role in physics discoveries related to new facilities.  The treatment of corrupted data in imaging and image processing is also a relevant topic.</li> 
<li> Design of detectors represents an important area of applications for ML/AI methods in nuclear physics.</li>
<li> Many of the above classification problems have also have direct application in theoretical nuclear physics (including Lattice QCD calculations).</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec9">More examples  </h2>

<ul>
<li> An important application of AI/L methods is to improve the estimation of bias or uncertainty due to the introduction of or lack of physical constraints in various theoretical models.</li>
<li> In theory, we expect to use AI/ML algorithms and methods to improve our knowledged about  correlations of physical model parameters in data for quantum many-body systems. Deep learning methods like Boltzmann machines and various types of Recurrent Neural networks show great promise in circumventing the exploding dimensionalities encountered in quantum mechanical many-body studies.</li> 
<li> Merging a frequentist approach (the standard path in ML theory) with a Bayesian approach, has the potential to infer better probabilitity distributions and error estimates. As an example, methods for fast Monte-Carlo- based Bayesian computation of nuclear density functionals show great promise in providing a better understanding</li> 
<li> Machine Learning and Quantum Computing is a very interesting avenue to explore.</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec10">Education and Work force development </h2>

<p>
AI, ML, statistical data analysis and related areas are expected to
play an ever-increasing role in many areas, from fundamental and
applied research at universities and national laboratories to
applications and developments in both the private and the public
sectors.
Developing basic research activities in these frontier
computational technologies is thus of strategic importance for our
society&#8217;s capability to address future scientific problems. Transfer
of knowledge to other disciplines and sectors, as well as developing
lasting collaborations with partners outside the traditional
university sector, are themes we expect will benefit society at large
and that will play central roles. Nuclear Physics keeps attracting many brilliant young researchers and providing our work force with these competences and skills for solving complicated physics problems is a compelling task for our community.

<p>
More text will come.

<ul>
<li> In order to develop education and training efforts that target AI and ML related methods applied to Nuclear Physics, we  organized in 2019 a four day long  FRIB-TA workshop on ML methods in Nuclear physics at the NSCL/FRIB, with more than 100 participants.</li>
<li> In 2020 several of us (Bazin, Hjorth-Jensen and Liddick) will teach a three-week long Nuclear Talent course on Machine Learning and Data Analysis applied to nuclear physics.</li> 
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec11">References </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>

<ul>
<li> An excellent reference, <a href="https://arxiv.org/abs/1803.08823" target="_blank">Mehta et al.</a> and <a href="https://www.sciencedirect.com/science/article/pii/S0370157319300766?via%3Dihub" target="_blank">Physics Reports (2019)</a>.</li>
<li> <a href="https://arxiv.org/abs/1903.10563" target="_blank">Machine Learning and the Physical Sciences by Carleo et al</a></li>
<li> <a href="https://arxiv.org/pdf/1909.02487.pdf" target="_blank">Many-electron systems with Deep Learning</a></li>
<li> <a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.120.156001" target="_blank">Every issue of Physical Review Letters has now one or more articles on ML</a></li>
<li> <a href="https://github.com/copperwire/thesis/blob/master/main.pdf" target="_blank">Classifying Nuclear Physics  experiments from the NSCL</a></li>
<li> <a href="https://github.com/bsamseth/qflow" target="_blank">Software and thesis on many-body methods and Machine Learning</a></li>
<li> <a href="https://github.com/CompPhysics/MachineLearning" target="_blank">Books and lectures notes</a> and see also the course <a href="https://www.uio.no/studier/emner/matnat/fys/FYS-STK4155/h18/index.html" target="_blank">FYS-STK3155/4155</a></li>
</ul>
</div>


<p>

<!-- ------------------- end of main content --------------- -->


</body>
</html>
    

